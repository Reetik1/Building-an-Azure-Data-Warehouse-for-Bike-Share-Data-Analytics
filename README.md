# Building-an-Azure-Data-Warehouse-for-Bike-Share-Data-Analytics


Project Overview
This project demonstrates the implementation of a modern cloud-based data warehouse solution using Microsoft Azure services. The project involves designing and implementing a complete ETL (Extract, Transform, Load) pipeline that transforms operational bike share data from a PostgreSQL database into a dimensional data warehouse optimized for analytics.
Business Context
The bike share company requires analytical capabilities to understand:

Trip patterns and rider behavior
Payment trends and revenue analysis
Station utilization and performance
Temporal patterns in bike usage

Architecture Overview
PostgreSQL (OLTP) â†’ Azure Blob Storage â†’ Azure Synapse Analytics â†’ Star Schema Data Warehouse
Technology Stack

Source System: PostgreSQL Database
Data Lake: Azure Blob Storage
Data Warehouse: Azure Synapse Analytics (Serverless SQL Pool)
ETL Tool: Azure Synapse Pipelines
Analytics: Star Schema Dimensional Model

Data Model
Star Schema Design
The data warehouse implements a star schema with the following structure:
Fact Tables

fact_trip

Primary measures: Trip Duration, Rider Age at Trip
Dimensions: Date, Rider, Start Station, End Station


fact_payment

Primary measures: Payment Amount
Dimensions: Date, Rider



Dimension Tables

dim_rider: Rider demographics and membership details
dim_station: Station location and capacity information
dim_date: Time hierarchy for temporal analysis

Source Data Statistics

Payment Records: 1,946,607 transactions
Rider Records: 75,000 unique riders
Station Records: 838 bike stations
Trip Records: 1,048,576 completed trips

Project Implementation
Task 1: Azure Infrastructure Setup

âœ… Created Azure Database for PostgreSQL
âœ… Provisioned Azure Synapse Analytics workspace
âœ… Configured serverless SQL pool for data warehouse operations

Task 2: Dimensional Data Modeling

âœ… Analyzed business requirements
âœ… Designed star schema with 2 fact tables and 3 dimension tables
âœ… Optimized for analytical query performance

Task 3: Source Data Preparation

âœ… Populated PostgreSQL with bike share operational data
âœ… Verified data integrity across all source tables
âœ… Established baseline for ETL validation

Task 4: Data Extraction

âœ… Implemented Azure Synapse pipeline for data extraction
âœ… Successfully extracted 4 source tables to Azure Blob Storage
âœ… Generated CSV files: public.payment.csv, public.rider.csv, public.station.csv, public.trip.csv

Task 5: Data Loading (Staging Layer)

âœ… Created external tables pointing to Blob Storage files
âœ… Implemented serverless SQL pool external table architecture
âœ… Established staging layer for data transformation

Task 6: Data Transformation (CETAS Implementation)

âœ… Developed CETAS (Create External Table As Select) scripts
âœ… Transformed staging data into dimensional model
âœ… Created optimized fact and dimension tables

Technical Highlights
ETL Pipeline Features

Serverless Architecture: Cost-effective serverless SQL pool implementation
External Tables: Efficient data processing without data movement
CETAS Operations: Parallel data transformation and materialization
Star Schema: Optimized dimensional model for analytical queries

Data Quality & Validation

Source Validation: Verified data completeness in PostgreSQL
Pipeline Monitoring: Tracked extraction success in Blob Storage
Transformation Validation: Confirmed dimensional model accuracy
Performance Testing: Validated query response times

File Structure
ğŸ“ azure-data-warehouse-project/
â”œâ”€â”€ ğŸ“„ README.md
â”œâ”€â”€ ğŸ“ sql-scripts/
â”‚   â”œâ”€â”€ ğŸ“ load/ (External table creation)
â”‚   â”‚   â”œâ”€â”€ staging_payment.sql
â”‚   â”‚   â”œâ”€â”€ staging_rider.sql
â”‚   â”‚   â”œâ”€â”€ staging_station.sql
â”‚   â”‚   â””â”€â”€ staging_trip.sql
â”‚   â””â”€â”€ ğŸ“ transform/ (CETAS scripts)
â”‚       â”œâ”€â”€ ğŸ“ fact-tables/
â”‚       â”‚   â”œâ”€â”€ fact_trip.sql
â”‚       â”‚   â””â”€â”€ fact_payment.sql
â”‚       â””â”€â”€ ğŸ“ dimension-tables/
â”‚           â”œâ”€â”€ dim_rider.sql
â”‚           â”œâ”€â”€ dim_station.sql
â”‚           â””â”€â”€ dim_date.sql
â”œâ”€â”€ ğŸ“ documentation/
â”‚   â”œâ”€â”€ ğŸ“ diagrams/
â”‚   â”‚   â””â”€â”€ star_schema_design.png
â”‚   â””â”€â”€ ğŸ“ screenshots/
â”‚       â”œâ”€â”€ azure_blob_storage.png
â”‚       â”œâ”€â”€ synapse_workspace.png
â”‚       â””â”€â”€ data_validation.png
â””â”€â”€ ğŸ“ data-setup/
    â””â”€â”€ ProjectDataToPostgres.py
Key Achievements

Scalable Architecture: Implemented serverless data warehouse capable of handling millions of records
Cost Optimization: Utilized pay-per-query serverless model for optimal cost efficiency
Performance Optimization: Star schema design enables sub-second analytical queries
Data Governance: Established clear data lineage from source to warehouse
Automation: Fully automated ETL pipeline with minimal manual intervention

Business Impact
This data warehouse enables the bike share company to:

Optimize Station Placement: Analyze trip patterns to identify high-demand locations
Revenue Analysis: Track payment trends and identify revenue opportunities
Operational Efficiency: Monitor bike utilization and maintenance schedules
Customer Insights: Understand rider behavior and preferences

Technical Skills Demonstrated

Cloud Architecture: Azure Synapse Analytics, Blob Storage, PostgreSQL
Data Modeling: Star schema design, dimensional modeling principles
ETL Development: Pipeline design, data transformation, CETAS operations
SQL Expertise: Advanced T-SQL, external tables, serverless computing
Data Engineering: End-to-end data pipeline implementation

Future Enhancements

Real-time Streaming: Implement Azure Stream Analytics for real-time data processing
Machine Learning: Integrate Azure ML for predictive analytics
Advanced Analytics: Power BI dashboard development for executive reporting
Data Governance: Implement Azure Purview for data catalog and lineage
